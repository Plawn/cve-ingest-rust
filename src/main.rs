// use std::fs::File;

use ::futures::future::Fuse;
use ::futures::Future;
use ::futures::FutureExt;
use ::futures::StreamExt;
use ::futures::TryFutureExt;
use async_std::task::block_on;
use cve_ingest_rust::bulk_update;
use cve_ingest_rust::BulkUpdate;
// use async_std::task;
use flate2::read::GzDecoder;
use pipe::pipe;
// use async_compression::futures::bufread::GzipDecoder;
use ::futures::future::join_all;
use ::futures::future::try_join_all;
use ::futures::join;
use ::futures::stream::FuturesUnordered;
use ::futures::TryStreamExt;
use async_compression::tokio::bufread::GzipDecoder;
use mongodb::bson::doc;
use mongodb::bson::from_document;
use mongodb::bson::oid::ObjectId;
use mongodb::bson::to_bson;
use mongodb::bson::to_document;
use mongodb::bson::Document;
use mongodb::options::ClientOptions;
use mongodb::options::InsertManyOptions;
use mongodb::options::SelectionCriteria;
use mongodb::options::UpdateOptions;
use mongodb::Client;
use mongodb::Database;
use serde::de::DeserializeOwned;
use tokio::pin;
// use ::futures::stream::TryStreamExt;
use std::borrow::Borrow;
use std::pin::Pin;
use std::sync::atomic::AtomicI32;
use std::sync::atomic::Ordering;
use std::sync::Arc;
use tokio::io::AsyncBufReadExt;
use tokio_util::compat::FuturesAsyncReadCompatExt;
// use futures_util::stream::ErrInto;
// use futures_util::TryStreamExt;
use std::collections::HashMap;
use std::error::Error;
use std::io::BufRead;
// use std::io::BufReader;
use std::iter::Map;
use std::thread;
// use tokio::io::AsyncBufReadExt;
// // use tokio::io::AsyncReadExt;
// use tokio_util::compat::FuturesAsyncReadCompatExt;
use tokio_util::io::StreamReader;

use chrono::{Duration, Utc};

use cve_ingest_rust::{prepare_date, Date, Root};
use jsonit::make_path;
use jsonit::JsonSeqIterator;
use serde::Deserialize;
use serde_json::Value;
use tokio::task::futures;

struct Window {
    start: Date,
    end: Date,
}

fn get_url(window: &Window, start_index: u32) -> String {
    // let url = "https://services.nvd.nist.gov/rest/json/cves/2.0/?lastModStartDate=2023-10-29T13:32:53.000%2B01:00&lastModEndDate=2023-10-29T21:32:53.000%2B01:00&startIndex=0";
    let url = format!(
        "https://services.nvd.nist.gov/rest/json/cves/2.0/?lastModStartDate={}&lastModEndDate={}&startIndex={}", prepare_date(&window.start), prepare_date(&window.end), start_index);
    return url;
}

struct Cpe {}

async fn do_window(w: &Window) -> Result<(), Box<dyn std::error::Error>> {
    let url = get_url(&w, 0);
    println!("{}", &url);
    let resp = reqwest::get(url).await?.json::<Root>().await?;
    println!("{:#?}", resp);
    Ok(())
}

// split date interval
fn get_windows() -> Vec<Window> {
    let mut res = vec![];
    let mut start = Utc::now();
    let end = Utc::now();
    start = start.checked_sub_signed(Duration::hours(8)).unwrap();
    let w = Window { start, end };
    res.push(w);
    return res;
}

fn get_cpes() -> (
    tokio::sync::mpsc::Receiver<CPE>,
    tokio::task::JoinHandle<()>,
) {
    use tokio::sync::mpsc;
    const CPE_URL: &str = "https://nvd.nist.gov/feeds/json/cpematch/1.0/nvdcpematch-1.0.json.gz";
    let (tx, rx) = mpsc::channel(5);
    let prepared_prefix = make_path("matches");
    let h: tokio::task::JoinHandle<()> = tokio::task::spawn_blocking(move || {
        let response = reqwest::blocking::get(CPE_URL).unwrap();

        let d = GzDecoder::new(response);
        // let r = jsonit::ReaderIter::new(buf_reader.lines());
        let it = JsonSeqIterator::<'_, _, CPE>::new(d, &prepared_prefix);
        // let mut chunk = Vec::new();

        for item in it.take(10_000) {
            match tx.blocking_send(item.unwrap()) {
                Ok(_) => {}
                Err(e) => {
                    println!("{}", e);
                    break;
                }
            }
        }
    });
    return (rx, h);
}

#[derive(Deserialize, Debug, serde::Serialize)]
struct CpeName {
    cpe23Uri: String,
}

#[derive(Deserialize, Debug, serde::Serialize)]
struct CPE {
    cpe23Uri: String,
    cpe_name: Vec<CpeName>,
}

async fn get_db() -> Result<Pin<Box<Database>>, mongodb::error::Error> {
    let url = "mongodb://siga.wks.msy.sds.safran:26000";
    let db_name = "newcvedb";
    let client_options = ClientOptions::parse(url).await?;
    let client = Client::with_options(client_options)?;
    let db = Box::pin(client.database(db_name));
    Ok(db)
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    let pool = rusty_pool::Builder::new().core_size(2).max_size(2).build();
    let cpe_collection: &str = "r_cpes";
    let db = get_db().await?;
    let collection = db.collection::<CPE>(cpe_collection);
    let chunk_size = 5000;
    let (mut rx, download_handle) = get_cpes();
    let mut docs: Vec<CPE> = vec![];
    let mut i = 0;
    use std::time::Instant;
    let options = Some(UpdateOptions::builder().upsert(true).build());
    // let mut handles:Vec<Pin<Box<dyn Future<Output = Result<BulkUpdateResult, mongodb::error::Error>>>>> = vec![];
    // let mut running = vec![];
    let pushed: Arc<AtomicI32> = Arc::new(AtomicI32::new(0));
    let prepared: Arc<AtomicI32> = Arc::new(AtomicI32::new(0));

    while let Some(message) = rx.recv().await {
        docs.push(message);
        i += 1;
        if docs.len() == chunk_size {
            // db.run_command(command, selection_criteria)
            // collection.insert_many(docs, None).await?;
            let start = Instant::now();
            let upsert = docs
                .iter()
                .map(|e| {
                    let o = options.clone();
                    let query = doc! { "cpe23Uri":  e.cpe23Uri.clone() };
                    BulkUpdate {
                        query,
                        update: to_document(e).unwrap(),
                        options: o,
                    }
                })
                .collect::<Vec<_>>();
            let duration = start.elapsed();
            println!("prepare took: {}", &duration.as_millis());
            prepared.fetch_add(1, Ordering::SeqCst);
            let clone = pushed.clone();
            let d = db.clone();
            pool.execute(move || {
                block_on(async move {
                    async move {
                        println!("pushing chunk: {}", i);
                        let start = Instant::now();
                        // clone.fetch_add(1, Ordering::SeqCst);
                        let res = bulk_update(&d, cpe_collection, upsert).await;
                        match res {
                            Ok(_) => {
                                // nothing to do
                                clone.fetch_add(1, Ordering::SeqCst);
                            }
                            Err(e) => match *e.kind {
                                mongodb::error::ErrorKind::Command(err) => {
                                    if err.code_name == "BSONObjectTooLarge" {
                                        // retry by splitting the set in two
                                        println!("too large");
                                    }
                                }
                                _ => todo!(),
                            },
                        }
                        let duration = start.elapsed();
                        println!("insert took: {}", &duration.as_millis());
                    }
                    .await
                });
            });

            docs = vec![];
        }
    }

    // try_join_all(running).await.unwrap();

    // push remaining
    if docs.len() > 0 {
        collection.insert_many(docs, None).await?;
    }

    download_handle.await?;
    async_std::task::spawn_blocking(move || {
        pool.join();
    })
    .await;

    println!("prepared: {:?}", &prepared);
    println!("pushed: {:?}", &pushed);
    Ok(())
}
