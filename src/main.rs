use async_std::task::block_on;
use chrono::{Duration, Utc};
use cve_ingest_rust::{bulk_update, BulkUpdate};
use cve_ingest_rust::{prepare_date, Date, Root};
use flate2::read::GzDecoder;
use jsonit::make_path;
use jsonit::JsonSeqIterator;
use mongodb::bson::{doc, to_document};
use mongodb::options::{ClientOptions, UpdateOptions};
use mongodb::{Client, Database};
use serde::Deserialize;
use std::error::Error;
use std::pin::Pin;
use std::sync::atomic::AtomicI32;
use std::sync::Arc;
use std::time::Instant;

struct Window {
    start: Date,
    end: Date,
}

fn get_url(window: &Window, start_index: u32) -> String {
    // let url = "https://services.nvd.nist.gov/rest/json/cves/2.0/?lastModStartDate=2023-10-29T13:32:53.000%2B01:00&lastModEndDate=2023-10-29T21:32:53.000%2B01:00&startIndex=0";
    let url = format!(
        "https://services.nvd.nist.gov/rest/json/cves/2.0/?lastModStartDate={}&lastModEndDate={}&startIndex={}", prepare_date(&window.start), prepare_date(&window.end), start_index);
    url
}

struct Cpe {}

async fn do_window(w: &Window) -> Result<(), Box<dyn std::error::Error>> {
    let url = get_url(w, 0);
    println!("{}", &url);
    let resp = reqwest::get(url).await?.json::<Root>().await?;
    println!("{:#?}", resp);
    Ok(())
}

// split date interval
fn get_windows() -> Vec<Window> {
    let mut res = vec![];
    let mut start = Utc::now();
    let end = Utc::now();
    start = start.checked_sub_signed(Duration::hours(8)).unwrap();
    let w = Window { start, end };
    res.push(w);
    res
}

fn get_cpes() -> (
    tokio::sync::mpsc::Receiver<CPE>,
    tokio::task::JoinHandle<()>,
) {
    use tokio::sync::mpsc;
    const CPE_URL: &str = "https://nvd.nist.gov/feeds/json/cpematch/1.0/nvdcpematch-1.0.json.gz";
    let (tx, rx) = mpsc::channel(32);
    let prepared_prefix = make_path("matches");
    let h: tokio::task::JoinHandle<()> = tokio::task::spawn_blocking(move || {
        let response = reqwest::blocking::get(CPE_URL).unwrap();
        let gz_decoder = GzDecoder::new(response);
        let json_iterator = JsonSeqIterator::<'_, _, CPE>::new(gz_decoder, &prepared_prefix);

        for item in json_iterator {
            match tx.blocking_send(item.unwrap()) {
                Ok(_) => {}
                Err(e) => {
                    println!("{}", e);
                    break;
                }
            }
        }
    });
    (rx, h)
}

#[derive(Deserialize, Debug, serde::Serialize)]
struct CpeName {
    #[serde(rename = "cpe23Uri")]
    cpe_23_uri: String,
}

#[derive(Deserialize, Debug, serde::Serialize)]
struct CPE {
    #[serde(rename = "cpe23Uri")]
    cpe_23_uri: String,
    cpe_name: Vec<CpeName>,
}

async fn get_db() -> Result<Database, mongodb::error::Error> {
    let url = "mongodb://siga.wks.msy.sds.safran:26000";
    let db_name = "newcvedb";
    let client_options = ClientOptions::parse(url).await?;
    let client = Client::with_options(client_options)?;
    let db = client.database(db_name);
    Ok(db)
}

fn do_one_vec(
    docs: Vec<BulkUpdate>,
    db: Arc<Database>,
    cpe_collection: &str,
    i: i32,
    pool: Arc<rusty_pool::ThreadPool>,
) {
    let name = cpe_collection.to_owned();
    let d = db.clone();
    pool.clone().execute(move || {
        block_on(async move {
            println!("pushing chunk: {}", i);
            let start = Instant::now();
            // clone.fetch_add(1, Ordering::SeqCst);
            let res = bulk_update(&d, &name, &mut docs.iter()).await;
            match res {
                Ok(_) => {
                    // nothing to do
                }
                Err(e) => {
                    // TODO: retry by splitting the set in two
                    // do_one_vec(docs.split(pred));
                    let len = docs.len() / 2;
                    use itertools::Itertools;
                    println!("too large, going lower: {}", len);
                    for chunk in docs.chunks(len) {
                        let v = chunk.iter().map(|e| e.to_owned()).collect_vec();
                        do_one_vec(v, db.clone(), &name, i, pool.clone());
                    }
                }
            }
            let duration = start.elapsed();
            println!("insert took: {}", &duration.as_millis());
        });
    });
}

fn prepare_bulk_operation(cpe: CPE) -> BulkUpdate {
    let options = Some(UpdateOptions::builder().upsert(true).build());
    let query = doc! { "cpe23Uri":  cpe.cpe_23_uri.clone() };
    let update = BulkUpdate {
        query,
        update: to_document(&cpe).unwrap(),
        options,
    };
    update
}

async fn update_cpes(pool: rusty_pool::ThreadPool) -> Result<(), Box<dyn Error>> {
    let cpe_collection: &str = "r_cpes";
    let cloned_pool = Arc::new(pool);
    let db = Arc::new(get_db().await?);
    let chunk_size = 5000;
    let (mut rx, download_handle) = get_cpes();
    let mut docs: Vec<BulkUpdate> = vec![];
    let mut i: i32 = 0;

    while let Some(message) = rx.recv().await {
        let update = prepare_bulk_operation(message);
        docs.push(update);
        i += 1;
        if docs.len() == chunk_size {
            do_one_vec(docs, db.clone(), cpe_collection, i, cloned_pool.clone());
            println!("got chunk");
            docs = vec![];
        }
    }

    println!("remaining: {}", docs.len());
    // push remaining
    if !docs.is_empty() {
        do_one_vec(docs, db.clone(), cpe_collection, i, cloned_pool.clone());
    }

    download_handle.await?;
    async_std::task::spawn_blocking(move || {
        cloned_pool.join();
    })
    .await;

    Ok(())
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    let pool = rusty_pool::Builder::new().core_size(2).max_size(2).build();
    let r = update_cpes(pool).await;
    r
}
