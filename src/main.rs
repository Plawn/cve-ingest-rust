// use std::fs::File;

use ::futures::future::Fuse;
use ::futures::Future;
use ::futures::FutureExt;
use ::futures::StreamExt;
use ::futures::TryFutureExt;
use async_std::task::block_on;
// use async_std::task;
use flate2::read::GzDecoder;
use pipe::pipe;
// use async_compression::futures::bufread::GzipDecoder;
use ::futures::future::join_all;
use ::futures::future::try_join_all;
use ::futures::join;
use ::futures::stream::FuturesUnordered;
use ::futures::TryStreamExt;
use async_compression::tokio::bufread::GzipDecoder;
use mongodb::bson::doc;
use mongodb::bson::from_document;
use mongodb::bson::oid::ObjectId;
use mongodb::bson::to_bson;
use mongodb::bson::to_document;
use mongodb::bson::Document;
use mongodb::options::ClientOptions;
use mongodb::options::InsertManyOptions;
use mongodb::options::SelectionCriteria;
use mongodb::options::UpdateOptions;
use mongodb::Client;
use mongodb::Database;
use serde::de::DeserializeOwned;
use tokio::pin;
// use ::futures::stream::TryStreamExt;
use std::borrow::Borrow;
use std::pin::Pin;
use std::sync::atomic::AtomicI32;
use std::sync::atomic::Ordering;
use std::sync::Arc;
use tokio::io::AsyncBufReadExt;
use tokio_util::compat::FuturesAsyncReadCompatExt;
// use futures_util::stream::ErrInto;
// use futures_util::TryStreamExt;
use std::collections::HashMap;
use std::error::Error;
use std::io::BufRead;
// use std::io::BufReader;
use std::iter::Map;
use std::thread;
// use tokio::io::AsyncBufReadExt;
// // use tokio::io::AsyncReadExt;
// use tokio_util::compat::FuturesAsyncReadCompatExt;
use tokio_util::io::StreamReader;

use chrono::{Duration, Utc};

use cve_ingest_rust::{prepare_date, Date, Root};
use jsonit::make_path;
use jsonit::JsonSeqIterator;
use serde::Deserialize;
use serde_json::Value;
use tokio::task::futures;

struct Window {
    start: Date,
    end: Date,
}

fn get_url(window: &Window, start_index: u32) -> String {
    // let url = "https://services.nvd.nist.gov/rest/json/cves/2.0/?lastModStartDate=2023-10-29T13:32:53.000%2B01:00&lastModEndDate=2023-10-29T21:32:53.000%2B01:00&startIndex=0";
    let url = format!(
        "https://services.nvd.nist.gov/rest/json/cves/2.0/?lastModStartDate={}&lastModEndDate={}&startIndex={}", prepare_date(&window.start), prepare_date(&window.end), start_index);
    return url;
}

struct Cpe {}

async fn do_window(w: &Window) -> Result<(), Box<dyn std::error::Error>> {
    let url = get_url(&w, 0);
    println!("{}", &url);
    let resp = reqwest::get(url).await?.json::<Root>().await?;
    println!("{:#?}", resp);
    Ok(())
}

// split date interval
fn get_windows() -> Vec<Window> {
    let mut res = vec![];
    let mut start = Utc::now();
    let end = Utc::now();
    start = start.checked_sub_signed(Duration::hours(8)).unwrap();
    let w = Window { start, end };
    res.push(w);
    return res;
}

fn get_cpes() -> (
    tokio::sync::mpsc::Receiver<CPE>,
    tokio::task::JoinHandle<()>,
) {
    use tokio::sync::mpsc;
    const CPE_URL: &str = "https://nvd.nist.gov/feeds/json/cpematch/1.0/nvdcpematch-1.0.json.gz";
    let (tx, rx) = mpsc::channel(32);
    let prefix = "matches";
    let prepared_prefix = make_path(prefix);
    let h = tokio::task::spawn_blocking(move || {
        let response2 = reqwest::blocking::get(CPE_URL).unwrap();

        let d = GzDecoder::new(response2);
        // let r = jsonit::ReaderIter::new(buf_reader.lines());
        let it = JsonSeqIterator::<'_, _, CPE>::new(d, &prepared_prefix);
        // let mut chunk = Vec::new();

        for item in it {
            match tx.blocking_send(item.unwrap()) {
                Ok(_) => {}
                Err(e) => {
                    println!("{}", e);
                    break;
                }
            }
        }
    });
    return (rx, h);
}

#[derive(Deserialize, Debug, serde::Serialize)]
struct CpeName {
    cpe23Uri: String,
}

#[derive(Deserialize, Debug, serde::Serialize)]
struct CPE {
    cpe23Uri: String,
    cpe_name: Vec<CpeName>,
}
#[derive(Debug, Deserialize)]
pub struct BulkUpdate {
    pub query: Document,
    pub update: Document,
    pub options: Option<UpdateOptions>,
}
#[derive(Debug, Deserialize)]
pub struct BulkUpdateUpsertResult {
    pub index: u64,
    pub id: ObjectId,
}
#[derive(Debug, Deserialize)]
pub struct BulkUpdateResult {
    // pub nb_affected: u64,
    // pub nb_modified: u64,
    // pub upserted: Vec<BulkUpdateUpsertResult>,
}

pub type MongoResult<T> = Result<T, mongodb::error::Error>;

pub async fn bulk_update<V, U>(
    db: &Database,
    collection_name: &str,
    updates: V,
) -> MongoResult<BulkUpdateResult>
where
    V: Borrow<Vec<U>>,
    U: Borrow<BulkUpdate>,
{
    let updates = updates.borrow();
    let mut update_docs = Vec::with_capacity(updates.len());
    for u in updates {
        let u = u.borrow();
        let mut doc = doc! {
            "q": &u.query,
            "u": &u.update,
            "multi": false,
        };
        if let Some(options) = &u.options {
            if let Some(ref upsert) = options.upsert {
                doc.insert("upsert", upsert);
            }
            if let Some(ref collation) = options.collation {
                doc.insert("collation", to_bson(collation)?);
            }
            if let Some(ref array_filters) = options.array_filters {
                doc.insert("arrayFilters", array_filters);
            }
            if let Some(ref hint) = options.hint {
                doc.insert("hint", to_bson(hint)?);
            }
        }
        update_docs.push(doc);
    }
    let mut command = doc! {
        "update": collection_name,
        "updates": update_docs,
    };
    if let Some(ref write_concern) = db.write_concern() {
        command.insert("writeConcern", to_bson(write_concern)?);
    }
    let selection_criteria: Option<SelectionCriteria> = db.selection_criteria().cloned();
    let res = db.run_command(command, selection_criteria).await?;
    Ok(from_document(res)?)
}

// use crate::task::JoinHandle;

// type Running = Pin<Box<Fuse<impl Future<Output = Result<BulkUpdateResult, Error>>>>>;
// type ToStart = Vec<JoinHandle<Result<BulkUpdateResult, mongodb::error::Error>>>;
// enum Handle {
//     Running(Pin<Box<Fuse<impl Future<Output = Result<BulkUpdateResult, Error>>>>>),
//     ToStart(ToStart),
// }

async fn get_db() -> Result<Pin<Box<Database>>, mongodb::error::Error> {
    let url = "mongodb://siga.wks.msy.sds.safran:26000";
    let db_name = "newcvedb";
    let client_options = ClientOptions::parse(url).await?;
    let client = Client::with_options(client_options)?;
    let db = Box::pin(client.database(db_name));
    Ok(db)
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    // // let reader = "".as_bytes();

    // let url = "https://f001.backblazeb2.com/file/korteur/hello-world.txt.gz";
    // let response = reqwest::get(url).await?;
    // let stream = response
    //     .bytes_stream()
    //     .map_err(|e| ::futures::io::Error::new(::futures::io::ErrorKind::Other, e))
    //     .into_async_read()
    //     .compat();
    // let gzip_decoder = GzipDecoder::new(stream);

    // // Print decompressed txt content
    // let mut buf_reader = tokio::io::BufReader::new(gzip_decoder);

    let pool = rusty_pool::Builder::new().core_size(2).max_size(2).build();
    let cpe_collection: &str = "r_cpes";
    let db = get_db().await?;
    let collection = db.collection::<CPE>(cpe_collection);
    let chunk_size = 5000;
    let (mut rx, _) = get_cpes();
    let mut docs: Vec<CPE> = vec![];
    let mut i = 0;
    use std::time::Instant;
    let options = Some(UpdateOptions::builder().upsert(true).build());
    // let mut handles:Vec<Pin<Box<dyn Future<Output = Result<BulkUpdateResult, mongodb::error::Error>>>>> = vec![];
    // let mut running = vec![];
    let pushed: Arc<AtomicI32> = Arc::new(AtomicI32::new(0));
    let prepared: Arc<AtomicI32> = Arc::new(AtomicI32::new(0));

    while let Some(message) = rx.recv().await {
        docs.push(message);
        i += 1;
        if docs.len() == chunk_size {
            // db.run_command(command, selection_criteria)
            // collection.insert_many(docs, None).await?;
            let start = Instant::now();
            let upsert = docs
                .iter()
                .map(|e| {
                    let o = options.clone();
                    let query = doc! { "cpe23Uri":  e.cpe23Uri.clone() };
                    BulkUpdate {
                        query,
                        update: to_document(e).unwrap(),
                        options: o,
                    }
                })
                .collect::<Vec<_>>();
            let duration = start.elapsed();
            println!("prepare took: {}", &duration.as_millis());
            prepared.fetch_add(1, Ordering::SeqCst);
            let clone = pushed.clone();
            let d = db.clone();
            pool.execute(move || {
                block_on(async move {
                    async move {
                        println!("pushing chunk: {}", i);
                        let start = Instant::now();
                        // clone.fetch_add(1, Ordering::SeqCst);
                        let res = bulk_update(&d, cpe_collection, upsert).await;
                        match res {
                            Ok(_) => {
                                // nothing to do
                                clone.fetch_add(1, Ordering::SeqCst);
                            }
                            Err(e) => match *e.kind {
                                mongodb::error::ErrorKind::Command(err) => {
                                    if err.code_name == "BSONObjectTooLarge" {
                                        // retry by splitting the set in two
                                        println!("too large");
                                    }
                                }
                                _ => todo!(),
                            },
                        }
                        let duration = start.elapsed();
                        println!("insert took: {}", &duration.as_millis());
                    }
                    .await
                });
            });

            docs = vec![];
        }
    }

    // try_join_all(running).await.unwrap();

    // push remaining
    if docs.len() > 0 {
        collection.insert_many(docs, None).await?;
    }

    async_std::task::spawn_blocking(move || {
        pool.join();
    })
    .await;
    println!("prepared: {:?}", &prepared);
    println!("pushed: {:?}", &pushed);
    Ok(())
}
