use async_std::task::block_on;
use chrono::{Duration, Utc};
use cve_ingest_rust::{bulk_update, BulkUpdate};
use cve_ingest_rust::{prepare_date, Date, Root};
use flate2::read::GzDecoder;
use ijson::IString;
use jsonit::make_path;
use jsonit::JsonSeqIterator;
use mongodb::bson::{doc, to_document};
use mongodb::options::{ClientOptions, UpdateOptions};
use mongodb::{Client, Database};
use serde::Deserialize;
use std::error::Error;
use std::pin::Pin;
use std::sync::atomic::AtomicI32;
use std::sync::Arc;
use std::time::Instant;

#[cfg(feature = "dhat-heap")]
#[global_allocator]
static ALLOC: dhat::Alloc = dhat::Alloc;

struct Window {
    start: Date,
    end: Date,
}

fn get_url(window: &Window, start_index: u32) -> String {
    // let url = "https://services.nvd.nist.gov/rest/json/cves/2.0/?lastModStartDate=2023-10-29T13:32:53.000%2B01:00&lastModEndDate=2023-10-29T21:32:53.000%2B01:00&startIndex=0";
    let url = format!(
        "https://services.nvd.nist.gov/rest/json/cves/2.0/?lastModStartDate={}&lastModEndDate={}&startIndex={}", prepare_date(&window.start), prepare_date(&window.end), start_index);
    url
}

struct Cpe {}

async fn do_window(w: &Window) -> Result<(), Box<dyn std::error::Error>> {
    let url = get_url(w, 0);
    println!("{}", &url);
    let resp = reqwest::get(url).await?.json::<Root>().await?;
    println!("{:#?}", resp);
    Ok(())
}

// split date interval
fn get_windows() -> Vec<Window> {
    let mut res = vec![];
    let mut start = Utc::now();
    let end = Utc::now();
    start = start.checked_sub_signed(Duration::hours(8)).unwrap();
    let w = Window { start, end };
    res.push(w);
    res
}


fn get_cpes(prepared_prefix:& Box<[u8]>) -> impl Iterator<Item = CPE> + '_ {
    const CPE_URL: &str = "https://nvd.nist.gov/feeds/json/cpematch/1.0/nvdcpematch-1.0.json.gz";
    // let (tx, rx) = bounded(32);
    let response = reqwest::blocking::get(CPE_URL).unwrap();

    // use bytes::Buf;
    // let b = response.bytes().unwrap();
    // let gz_decoder = GzDecoder::new(b.reader());
    // let iter = jsonit::ReaderIter::new(gz_decoder).map(|e| e.unwrap());
    // let json_iterator = jsonit::stream_read_items_at(iter, "matches");

    let gz_decoder = GzDecoder::new(response);
    let json_iterator = JsonSeqIterator::new(gz_decoder, &prepared_prefix);
    json_iterator.map(|e| e.unwrap())
}

#[derive(Deserialize, Debug, serde::Serialize)]
struct CpeName {
    #[serde(rename = "cpe23Uri")]
    cpe_23_uri: String,
}

#[derive(Deserialize, Debug, serde::Serialize)]
struct CPE {
    #[serde(rename = "cpe23Uri")]
    cpe_23_uri: IString,
    cpe_name: Vec<CpeName>,
}

async fn get_db() -> Result<Database, mongodb::error::Error> {
    let url = "mongodb://siga.wks.msy.sds.safran:26000";
    let db_name = "newcvedb";
    let client_options = ClientOptions::parse(url).await?;
    let client = Client::with_options(client_options)?;
    let db = client.database(db_name);
    Ok(db)
}

fn do_one_vec(
    docs: Vec<BulkUpdate>,
    db: Arc<Database>,
    cpe_collection: &str,
    i: i32,
    pool: Arc<rusty_pool::ThreadPool>,
) {
    let name = cpe_collection.to_owned();
    let d = db.clone();
    block_on(async move {
        println!("pushing chunk: {}", i);
        let start = Instant::now();
        // clone.fetch_add(1, Ordering::SeqCst);
        let res = bulk_update(&d, &name, &mut docs.iter()).await;
        match res {
            Ok(_) => {
                // nothing to do
            }
            Err(e) => {
                // TODO: retry by splitting the set in two
                // do_one_vec(docs.split(pred));
                let len = docs.len() / 2;
                use itertools::Itertools;
                println!("Error {}, going lower: {}", e, len);
                for chunk in docs.chunks(len) {
                    // let v = chunk.iter().map(|e| e.to_owned()).collect_vec();
                    // do_one_vec(v, db.clone(), &name, i, pool.clone());
                }
            }
        }
        let duration = start.elapsed();
        println!("insert took: {}", &duration.as_millis());
    });
}

const BATCH_SIZE:usize = 2500;

fn prepare_bulk_operation(cpe: CPE) -> BulkUpdate {
    let options = Some(UpdateOptions::builder().upsert(true).build());
    let uri = cpe.cpe_23_uri.as_str();
    let query = doc! { "cpe23Uri":  uri };
    let update = BulkUpdate {
        query,
        update: to_document(&cpe).unwrap(),
        options,
    };
    update
}

async fn update_cpes(pool: rusty_pool::ThreadPool) -> Result<(), Box<dyn Error>> {
    let cpe_collection: &str = "r_cpes";
    let cloned_pool = Arc::new(pool);
    let db = Arc::new(get_db().await?);
    let prepared_prefix = make_path("matches");
    let it = get_cpes(&prepared_prefix);
    let mut docs: Vec<BulkUpdate> = Vec::with_capacity(BATCH_SIZE);
    let mut i: i32 = 0;

    for message in it {
        let update = prepare_bulk_operation(message);
        docs.push(update);
        i += 1;
        if docs.len() == BATCH_SIZE {
            do_one_vec(
                docs,
                db.clone(),
                cpe_collection,
                i,
                cloned_pool.clone(),
            );
            println!("got chunk");
            docs = Vec::with_capacity(BATCH_SIZE);
        }
    }

    println!("remaining: {}", docs.len());
    // push remaining
    if !docs.is_empty() {
        do_one_vec(docs, db.clone(), cpe_collection, i, cloned_pool.clone());
    }

    Ok(())
}

#[async_std::main]
async fn main() -> Result<(), Box<dyn Error>> {
    #[cfg(feature = "dhat-heap")]
    let _profiler = dhat::Profiler::new_heap();
    
    let pool = rusty_pool::Builder::new().core_size(2).max_size(2).build();
    let r = update_cpes(pool).await;
    r
}
